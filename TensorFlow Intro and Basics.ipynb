{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow installation using Anaconda.\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_7:0\", shape=(), dtype=float32) Tensor(\"Const_8:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creating a basic computational graph using a constant tensor.\n",
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0)\n",
    "\n",
    "# We've not ran the computational graph created above.\n",
    "# So we will not be getting any values for node1 and node2 as of yet.\n",
    "print(node1,node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run a computational graph (Flow) is done using sessions, as is seen below.\n",
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below exampes is using a bigger computational graph(flow).\n",
    "a = tf.constant(5)\n",
    "b = tf.constant(2)\n",
    "c = tf.constant(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing operations using constant tensors.\n",
    "d = tf.multiply(a,b)\n",
    "e = tf.add(c,b)\n",
    "\n",
    "f = tf.subtract(d,e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outs = 5\n"
     ]
    }
   ],
   "source": [
    "# Running the computational graph and saving the output for display.\n",
    "outs = sess.run(f)\n",
    "sess.close()\n",
    "print(\"outs = {}\".format(outs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder is a type of tensor that is a promise to provide a value later.\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing an operation on the declared tensored.\n",
    "# NOTE that the values of the tensors are not constant and yet initialized.\n",
    "adder_node = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "# Creating a new session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Running the computational graph and printing the output.\n",
    "# NOTE that the input is in the form of a dictionary and is take in pairs (a,b) as (1,2) and then (3,4).\n",
    "# Expected outputs: 1+2=3 and 3+4=7\n",
    "print(sess.run(adder_node,{a:[1,3],b:[2,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another type of tensor is Variables, they help add trainable parameters to a graph.\n",
    "# This helps in training models with the same variables but updating their values.\n",
    "\n",
    "# Weight variable - in lay man terms decide how important a feature is to add to the result.\n",
    "W = tf.Variable([.3],tf.float32)\n",
    "b = tf.Variable([-.3],tf.float32)\n",
    "\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "# Creating a simplistic model where the INPUT x is multiplies with WEIGHT W and a BIAS b is added.\n",
    "linear_model = W * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GLOBAL variables tensor needs to be initialised with values. The below function does that.\n",
    "# https://www.tensorflow.org/api_docs/python/tf/global_variables_initializer.\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the initialization using session.\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "# Running the linear model on INPUT x which is a dictionary of values and printing it's output.\n",
    "print(sess.run(linear_model, {x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is calculating the loss function and adjusting the model parameter.\n",
    "# i.e. WEIGHT W and BIAS b to fit the model on the data.\n",
    "# This helps understand and evaluate the model on training data.\n",
    "\n",
    "# y will provide the desired output values.\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# tf. square function SQUARES the ERROR linear_model - y (real output - desired output).\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "\n",
    "# tf.reduce_sum is used to sum all the sqaured error\n",
    "loss = tf.reduce_sum(squared_deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "# Run the loss function and print the error to help evaluate the model.\n",
    "print(sess.run(loss, {x:[1,2,3,4], y:[0,-1,-2,-3,]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent Algorithm is the simplest optimising function available.\n",
    "# Step size i.e. learning rate is 0.01.\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the training paramters to optimise i.e. minimze the loss.\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-initializing the variables.\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the trained optimiser to all the input model.\n",
    "for i in range (1000):\n",
    "    sess.run(train, {x:[1,2,3,4], y:[0,-1,-2,-3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# The new best suited values calculated for the model on training data are W = -0.9999969 and b = 0.99999082\n",
    "print(sess.run([W, b]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
